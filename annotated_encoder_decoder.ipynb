{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J5tgIb-fsjZd"
   },
   "source": [
    "This code was heavily influenced by the following:\n",
    "5.4-EXE-seq2seq-digits : Jupyter notebook that was provided in week 5,\n",
    "https://github.com/bentrevett/pytorch-seq2seq,\n",
    "https://github.com/bastings/annotated_encoder_decoder,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6213,
     "status": "ok",
     "timestamp": 1575405986862,
     "user": {
      "displayName": "Alexandros Dorodoulis",
      "photoUrl": "",
      "userId": "07816985308410186091"
     },
     "user_tz": -60
    },
    "id": "nfC2KkiXu4nd",
    "outputId": "b385b496-06e5-4bfe-c3e9-7979c9ae179a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
      "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.17.4)\n",
      "Requirement already up-to-date: matplotlib in /usr/local/lib/python3.6/dist-packages (3.1.2)\n",
      "Requirement already up-to-date: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.4.3)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.5)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch numpy matplotlib sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LpYJqpvTsT5x"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "uModMG0rsT6A"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import sacrebleu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6186,
     "status": "ok",
     "timestamp": 1575405986866,
     "user": {
      "displayName": "Alexandros Dorodoulis",
      "photoUrl": "",
      "userId": "07816985308410186091"
     },
     "user_tz": -60
    },
    "id": "QCdRmVowsT6J",
    "outputId": "981b024b-d86e-4fc0-cf99-b7c246eaf479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: False\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda:0\")  # or set to 'cpu'\n",
    "print(\"CUDA:\", USE_CUDA)\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GiVDUOGzsT6P"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sXJ0qGAYsT6S"
   },
   "source": [
    "\n",
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "D8SpjFDZsT6T"
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many\n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.trg_embed = trg_embed\n",
    "        self.generator = generator\n",
    "    def forward(self, src, trg, src_mask, trg_mask, src_lengths, trg_lengths):\n",
    "        \"\"\"Take in and process masked src and target sequences.\"\"\"\n",
    "        encoder_hidden, encoder_final = self.encode(src, src_mask, src_lengths)\n",
    "        return self.decode(\n",
    "            encoder_hidden, encoder_final, src_mask, trg, trg_mask\n",
    "        )\n",
    "    def encode(self, src, src_mask, src_lengths):\n",
    "        return self.encoder(self.src_embed(src), src_mask, src_lengths)\n",
    "    def decode(\n",
    "        self,\n",
    "        encoder_hidden,\n",
    "        encoder_final,\n",
    "        src_mask,\n",
    "        trg,\n",
    "        trg_mask,\n",
    "        decoder_hidden=None,\n",
    "        max_len=None,\n",
    "    ):\n",
    "        return self.decoder(\n",
    "            self.trg_embed(trg),\n",
    "            encoder_hidden,\n",
    "            encoder_final,\n",
    "            src_mask,\n",
    "            trg_mask,\n",
    "            hidden=decoder_hidden,\n",
    "            max_len=max_len,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EeOMNogDsT6a"
   },
   "source": [
    "\n",
    "Projects the pre-output layer ($x$ in the `forward` function below) to obtain the output layer, so that the final dimension is the target vocabulary size.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Dcoo05KmsT6b"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
    "    def __init__(self, hidden_size, vocab_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ivQgiTD9sT64"
   },
   "source": [
    "\n",
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bSuDKvuPsT66"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encodes a sequence of word embeddings\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.0):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        Applies a bidirectional GRU to sequence of embeddings x.\n",
    "        The input mini-batch x needs to be sorted by length.\n",
    "        x should have dimensions [batch, time, dim].\n",
    "        \"\"\"\n",
    "        packed = pack_padded_sequence(\n",
    "            x, lengths, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        output, final = self.rnn(packed)\n",
    "        output, _ = pad_packed_sequence(\n",
    "            output, batch_first=True, padding_value=0\n",
    "        )\n",
    "\n",
    "        # we need to manually concatenate the final states for both directions\n",
    "        fwd_final = final[0 : final.size(0) : 2]\n",
    "        bwd_final = final[1 : final.size(0) : 2]\n",
    "        final = torch.cat(\n",
    "            [fwd_final, bwd_final], dim=2\n",
    "        )  # [num_layers, batch, 2*dim]\n",
    "        return output, final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38dkONDqsT6-"
   },
   "source": [
    "\n",
    "### Decoder<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bhY-nNIesT7A"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"A conditional RNN decoder with attention.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        emb_size,\n",
    "        hidden_size,\n",
    "        attention,\n",
    "        num_layers=1,\n",
    "        dropout=0.5,\n",
    "        bridge=True,\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.attention = attention\n",
    "        self.dropout = dropout\n",
    "        self.rnn = nn.GRU(\n",
    "            emb_size + 2 * hidden_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        # to initialize from the final encoder state\n",
    "        self.bridge = (\n",
    "            nn.Linear(2 * hidden_size, hidden_size, bias=True)\n",
    "            if bridge\n",
    "            else None\n",
    "        )\n",
    "        self.dropout_layer = nn.Dropout(p=dropout)\n",
    "        self.pre_output_layer = nn.Linear(\n",
    "            hidden_size + 2 * hidden_size + emb_size, hidden_size, bias=False\n",
    "        )\n",
    "    def forward_step(\n",
    "        self, prev_embed, encoder_hidden, src_mask, proj_key, hidden\n",
    "    ):\n",
    "        \"\"\"Perform a single decoder step (1 word)\"\"\"\n",
    "\n",
    "        # compute context vector using attention mechanism\n",
    "        query = hidden[-1].unsqueeze(1)  # [#layers, B, D] -> [B, 1, D]\n",
    "        context, attn_probs = self.attention(\n",
    "            query=query, proj_key=proj_key, value=encoder_hidden, mask=src_mask\n",
    "        )\n",
    "\n",
    "        # update rnn hidden state\n",
    "        rnn_input = torch.cat([prev_embed, context], dim=2)\n",
    "        output, hidden = self.rnn(rnn_input, hidden)\n",
    "        pre_output = torch.cat([prev_embed, output, context], dim=2)\n",
    "        pre_output = self.dropout_layer(pre_output)\n",
    "        pre_output = self.pre_output_layer(pre_output)\n",
    "        return output, hidden, pre_output\n",
    "    def forward(\n",
    "        self,\n",
    "        trg_embed,\n",
    "        encoder_hidden,\n",
    "        encoder_final,\n",
    "        src_mask,\n",
    "        trg_mask,\n",
    "        hidden=None,\n",
    "        max_len=None,\n",
    "    ):\n",
    "        \"\"\"Unroll the decoder one step at a time.\"\"\"\n",
    "\n",
    "        # the maximum number of steps to unroll the RNN\n",
    "        if max_len is None:\n",
    "            max_len = trg_mask.size(-1)\n",
    "\n",
    "        # initialize decoder hidden state\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(encoder_final)\n",
    "\n",
    "        # pre-compute projected encoder hidden states\n",
    "        # (the \"keys\" for the attention mechanism)\n",
    "        # this is only done for efficiency\n",
    "        proj_key = self.attention.key_layer(encoder_hidden)\n",
    "\n",
    "        # here we store all intermediate hidden states and pre-output vectors\n",
    "        decoder_states = []\n",
    "        pre_output_vectors = []\n",
    "\n",
    "        # unroll the decoder RNN for max_len steps\n",
    "        for i in range(max_len):\n",
    "            prev_embed = trg_embed[:, i].unsqueeze(1)\n",
    "            output, hidden, pre_output = self.forward_step(\n",
    "                prev_embed, encoder_hidden, src_mask, proj_key, hidden\n",
    "            )\n",
    "            decoder_states.append(output)\n",
    "            pre_output_vectors.append(pre_output)\n",
    "        decoder_states = torch.cat(decoder_states, dim=1)\n",
    "        pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n",
    "        return decoder_states, hidden, pre_output_vectors  # [B, N, D]\n",
    "    def init_hidden(self, encoder_final):\n",
    "        \"\"\"Returns the initial decoder state,\n",
    "        conditioned on the final encoder state.\"\"\"\n",
    "        if encoder_final is None:\n",
    "            return None  # start with zeros\n",
    "        return torch.tanh(self.bridge(encoder_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fMXg83uCsT7E"
   },
   "source": [
    "\n",
    "### Attention\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "MV3PLvd9sT7F"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"Implements Bahdanau (MLP) attention\"\"\"\n",
    "    def __init__(self, hidden_size, key_size=None, query_size=None):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "\n",
    "        # We assume a bi-directional encoder so key_size is 2*hidden_size\n",
    "        key_size = 2 * hidden_size if key_size is None else key_size\n",
    "        query_size = hidden_size if query_size is None else query_size\n",
    "        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n",
    "        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n",
    "        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "        # to store attention scores\n",
    "        self.alphas = None\n",
    "    def forward(self, query=None, proj_key=None, value=None, mask=None):\n",
    "        assert mask is not None, \"mask is required\"\n",
    "\n",
    "        # We first project the query (the decoder state).\n",
    "        # The projected keys (the encoder states) were already pre-computated.\n",
    "        query = self.query_layer(query)\n",
    "\n",
    "        # Calculate scores.\n",
    "        scores = self.energy_layer(torch.tanh(query + proj_key))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        # Mask out invalid positions.\n",
    "        # The mask marks valid positions so we invert it using `mask & 0`.\n",
    "        scores.data.masked_fill_(mask == 0, -float(\"inf\"))\n",
    "\n",
    "        # Turn scores to probabilities.\n",
    "        alphas = F.softmax(scores, dim=-1)\n",
    "        self.alphas = alphas\n",
    "\n",
    "        # The context vector is the weighted sum of the values.\n",
    "        context = torch.bmm(alphas, value)\n",
    "\n",
    "        # context shape: [B, 1, 2D], alphas shape: [B, 1, M]\n",
    "        return context, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fdl87K6QsT7L"
   },
   "outputs": [],
   "source": [
    "def make_model(\n",
    "    src_vocab,\n",
    "    tgt_vocab,\n",
    "    emb_size=256,\n",
    "    hidden_size=512,\n",
    "    num_layers=1,\n",
    "    dropout=0.1,\n",
    "):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    attention = BahdanauAttention(hidden_size)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n",
    "        Decoder(\n",
    "            emb_size,\n",
    "            hidden_size,\n",
    "            attention,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "        ),\n",
    "        nn.Embedding(src_vocab, emb_size, padding_idx=0),\n",
    "        nn.Embedding(tgt_vocab, emb_size, padding_idx=0),\n",
    "        Generator(hidden_size, tgt_vocab),\n",
    "    )\n",
    "    return model.cuda() if USE_CUDA else model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "liKUcy4SsT7P"
   },
   "source": [
    "\n",
    "# Training<br>\n",
    "\n",
    "## Batches and Masking<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "E_SNhxuTsT7Q"
   },
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"\"\"Object for holding a batch of data with mask during training.\n",
    "    Input is a batch from a torch text iterator.\n",
    "    \"\"\"\n",
    "    def __init__(self, src, trg, pad_index=0):\n",
    "        src, src_lengths = src\n",
    "        self.src = src\n",
    "        self.src_lengths = src_lengths\n",
    "        self.src_mask = (src != pad_index).unsqueeze(-2)\n",
    "        self.nseqs = src.size(0)\n",
    "        self.trg = None\n",
    "        self.trg_y = None\n",
    "        self.trg_mask = None\n",
    "        self.trg_lengths = None\n",
    "        self.ntokens = None\n",
    "        if trg is not None:\n",
    "            trg, trg_lengths = trg\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_lengths = trg_lengths\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = self.trg_y != pad_index\n",
    "            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n",
    "        if USE_CUDA:\n",
    "            self.src = self.src.cuda()\n",
    "            self.src_mask = self.src_mask.cuda()\n",
    "            if trg is not None:\n",
    "                self.trg = self.trg.cuda()\n",
    "                self.trg_y = self.trg_y.cuda()\n",
    "                self.trg_mask = self.trg_mask.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9rvXNXofsT7U"
   },
   "source": [
    "\n",
    "## Training Loop<br>\n",
    "The code below trains the model for 1 epoch (=1 pass through the training data).<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Dg6BNbqHsT7W"
   },
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, loss_compute, print_every=50):\n",
    "    \"\"\"Standard Training and Logging Function\"\"\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    print_tokens = 0\n",
    "    for i, batch in enumerate(data_iter, 1):\n",
    "        out, _, pre_output = model.forward(\n",
    "            batch.src,\n",
    "            batch.trg,\n",
    "            batch.src_mask,\n",
    "            batch.trg_mask,\n",
    "            batch.src_lengths,\n",
    "            batch.trg_lengths,\n",
    "        )\n",
    "        loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        print_tokens += batch.ntokens\n",
    "        if model.training and i % print_every == 0:\n",
    "            elapsed = time.time() - start\n",
    "            print(\n",
    "                \"Epoch Step: %d Loss: %f Tokens per Sec: %f\"\n",
    "                % (i, loss / batch.nseqs, print_tokens / elapsed)\n",
    "            )\n",
    "            start = time.time()\n",
    "            print_tokens = 0\n",
    "    return math.exp(total_loss / float(total_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bh2mPUjrsT7c"
   },
   "source": [
    "\n",
    "## Synthetic Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "g177F3EbsT7d"
   },
   "outputs": [],
   "source": [
    "target_to_text = {\n",
    "    \"0\": \"0\",\n",
    "    \"1\": \"1\",\n",
    "    \"2\": \"two\",\n",
    "    \"3\": \"three\",\n",
    "    \"4\": \"four\",\n",
    "    \"5\": \"five\",\n",
    "    \"6\": \"six\",\n",
    "    \"7\": \"seven\",\n",
    "    \"8\": \"eight\",\n",
    "    \"9\": \"nine\",\n",
    "}\n",
    "input_characters = \" \".join(target_to_text.values())\n",
    "valid_characters = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\",] + list(\n",
    "    set(input_characters)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aaeoC9-8sT7i"
   },
   "outputs": [],
   "source": [
    "src_vocab_len = len(valid_characters)\n",
    "trg_vocab_len = len(target_to_text.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "o2rOJtb6sT7o"
   },
   "outputs": [],
   "source": [
    "def data_gen(\n",
    "    num_words=9,\n",
    "    batch_size=16,\n",
    "    num_batches=100,\n",
    "    min_length=3,\n",
    "    max_length=8,\n",
    "    pad_index=0,\n",
    "    eos_index=1,\n",
    "    sos_index=1,\n",
    "):\n",
    "    \"\"\"Generate random data for a src-tgt copy task.\"\"\"\n",
    "    for i in range(num_batches):\n",
    "        data = [\n",
    "            np.random.randint(\n",
    "                2,\n",
    "                num_words,\n",
    "                size=(np.random.randint(min_length, max_length + 1)),\n",
    "            )\n",
    "            for i in range(batch_size)\n",
    "        ]\n",
    "        for arr in data:\n",
    "            arr[-1] = eos_index\n",
    "            arr[0] = sos_index\n",
    "        trg_max_length = max([len(i) for i in data])\n",
    "        tmp = np.zeros((batch_size, trg_max_length), dtype=\"int64\")\n",
    "        trg_lengths = []\n",
    "        for i, arr in enumerate(data):\n",
    "            cur_len = len(arr)\n",
    "            trg_lengths.append(cur_len)\n",
    "            tmp[i, :cur_len] = arr\n",
    "        data = tmp\n",
    "        src = [\n",
    "            [\n",
    "                target_to_text[str(x)]\n",
    "                for x in i\n",
    "                if x not in (pad_index, eos_index, sos_index)\n",
    "            ]\n",
    "            for i in data\n",
    "        ]\n",
    "        src = [[valid_characters.index(el) for el in \" \".join(y)] for y in src]\n",
    "        src_max_len = max([len(i) for i in src])\n",
    "        src_lengths = []\n",
    "        tmp = np.zeros((batch_size, src_max_len), dtype=\"int64\")\n",
    "        for i, arr in enumerate(src):\n",
    "            cur_len = len(arr)\n",
    "            src_lengths.append(cur_len)\n",
    "            tmp[i, :cur_len] = arr\n",
    "        src = torch.from_numpy(tmp)\n",
    "        data = torch.from_numpy(data)\n",
    "        data = data.cuda() if USE_CUDA else data\n",
    "        trg = data\n",
    "        yield Batch(\n",
    "            (torch.LongTensor(src), src_lengths),\n",
    "            (torch.LongTensor(trg), trg_lengths),\n",
    "            pad_index=pad_index,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aT3Pq2eZsT7u"
   },
   "source": [
    "\n",
    "## Loss Computation\n",
    "  \n",
    "A simple loss compute and train function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3zKPw-mbsT7v"
   },
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(\n",
    "            x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1)\n",
    "        )\n",
    "        loss = loss / norm\n",
    "        if self.opt is not None:\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "        return loss.data.item() * norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2QU5Tc_sT71"
   },
   "source": [
    "\n",
    "### Printing examples<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "FQbJj6wZsT72"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(\n",
    "    model, src, src_mask, src_lengths, max_len=100, sos_index=1, eos_index=1\n",
    "):\n",
    "    \"\"\"Greedily decode a sentence.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n",
    "        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n",
    "        trg_mask = torch.ones_like(prev_y)\n",
    "    output = []\n",
    "    attention_scores = []\n",
    "    hidden = None\n",
    "    for i in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            out, hidden, pre_output = model.decode(\n",
    "                encoder_hidden,\n",
    "                encoder_final,\n",
    "                src_mask,\n",
    "                prev_y,\n",
    "                trg_mask,\n",
    "                hidden,\n",
    "            )\n",
    "\n",
    "            # we predict from the pre-output layer, which is\n",
    "            # a combination of Decoder state, prev emb, and context\n",
    "            prob = model.generator(pre_output[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data.item()\n",
    "        output.append(next_word)\n",
    "        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n",
    "        attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n",
    "    output = np.array(output)\n",
    "\n",
    "    # cut off everything starting from </s>\n",
    "    # (only when eos_index provided)\n",
    "    if eos_index is not None:\n",
    "        first_eos = np.where(output == eos_index)[0]\n",
    "        if len(first_eos) > 0:\n",
    "            output = output[: first_eos[0]]\n",
    "    return output, np.concatenate(attention_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YCJ7xtjGsT75"
   },
   "outputs": [],
   "source": [
    "def lookup_words(x, vocab=None):\n",
    "    if vocab is not None:\n",
    "        x = [vocab.itos[i] for i in x]\n",
    "    return [str(t) for t in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wkl5-IecsT7-"
   },
   "outputs": [],
   "source": [
    "def turn_num_to_text(nums):\n",
    "    return [valid_characters[num] for num in nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YfOttqobsT8B"
   },
   "outputs": [],
   "source": [
    "def print_examples(\n",
    "    example_iter,\n",
    "    model,\n",
    "    n=2,\n",
    "    max_len=100,\n",
    "    sos_index=1,\n",
    "    src_eos_index=None,\n",
    "    trg_eos_index=1,\n",
    "    src_vocab=None,\n",
    "    trg_vocab=None,\n",
    "):\n",
    "    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    hypotheses = []\n",
    "    alphas = []  \n",
    "    print()\n",
    "    if src_vocab is not None and trg_vocab is not None:\n",
    "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
    "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
    "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
    "    else:\n",
    "        src_eos_index = None\n",
    "        trg_sos_index = 1\n",
    "        trg_eos_index = 1\n",
    "    for i, batch in enumerate(example_iter):\n",
    "        src = batch.src.cpu().numpy()[0, :]\n",
    "        trg = batch.trg_y.cpu().numpy()[0, :]\n",
    "\n",
    "        # remove </s> (if it is there)\n",
    "        src = src[:-1] if src[-1] == src_eos_index else src\n",
    "        trg = trg[:-1] if trg[-1] == trg_eos_index else trg\n",
    "        result,alpha = greedy_decode(\n",
    "            model,\n",
    "            batch.src,\n",
    "            batch.src_mask,\n",
    "            batch.src_lengths,\n",
    "            sos_index=trg_sos_index,\n",
    "            eos_index=trg_eos_index,\n",
    "        )\n",
    "        match = 0\n",
    "        print(\"Example #%d\" % (i + 1))\n",
    "        print(\"Src : \", \"\".join(turn_num_to_text(src)))\n",
    "        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n",
    "        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n",
    "        count += 1\n",
    "        for i,s in enumerate(result):\n",
    "          if i > len(trg):\n",
    "            break\n",
    "          if s == trg[i]:\n",
    "            match +=1\n",
    "        print(\"Match: \", str(match/len(trg)) )\n",
    "        print()\n",
    "        if count == n:\n",
    "            break\n",
    "    hypotheses.append(result)\n",
    "    alphas.append(alpha)\n",
    "    return hypotheses,alphas,src,trg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SjJDIiiVsT8F"
   },
   "source": [
    "\n",
    "## Training the \"translation\" task\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Mf-aGh6qsT8G"
   },
   "outputs": [],
   "source": [
    "def train_trans_task():\n",
    "    num_words = 10\n",
    "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=0)\n",
    "    model = make_model(\n",
    "        src_vocab_len, trg_vocab_len, emb_size=64, hidden_size=128\n",
    "    )\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "    min_length = 4\n",
    "    max_length = 100\n",
    "    batch_size = 32\n",
    "    num_batches = 250\n",
    "    eval_data = list(\n",
    "        data_gen(\n",
    "            num_words=num_words,\n",
    "            batch_size=1,\n",
    "            num_batches=num_batches,\n",
    "            min_length=min_length,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "    )\n",
    "    dev_perplexities = []\n",
    "    if USE_CUDA:\n",
    "        model.cuda()\n",
    "    for epoch in range(10):\n",
    "        print(\"Epoch %d\" % epoch)\n",
    "        data = data_gen(\n",
    "            num_words=num_words,\n",
    "            batch_size=batch_size,\n",
    "            num_batches=num_batches,\n",
    "            min_length=min_length,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        # train\n",
    "        model.train()\n",
    "        run_epoch(\n",
    "            data, model, SimpleLossCompute(model.generator, criterion, optim)\n",
    "        )\n",
    "\n",
    "        # evaluate\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            perplexity = run_epoch(\n",
    "                eval_data,\n",
    "                model,\n",
    "                SimpleLossCompute(model.generator, criterion, None),\n",
    "            )\n",
    "            print(\"Evaluation perplexity: %f\" % perplexity)\n",
    "            dev_perplexities.append(perplexity)\n",
    "            hypotheses,alphas,src_ex,trg_ex=print_examples(eval_data, model, n=2, max_len=max_length)\n",
    "    return dev_perplexities,hypotheses,alphas,src_ex,trg_ex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fFdFGaDZsT8J"
   },
   "source": [
    "train the copy task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "7prSJ-KBsT8L",
    "outputId": "92ead8e6-f0dc-40e9-fd56-9207da781016"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Evaluation perplexity: 9.947699\n",
      "\n",
      "Example #1\n",
      "Src :  eight four nine six six eight three four eight four four nine six five nine nine four seven six three nine five seven seven three nine five six two five three seven six five two two four four eight three nine five five nine eight seven seven eight seven four five eight five\n",
      "Trg :  8 4 9 6 6 8 3 4 8 4 4 9 6 5 9 9 4 7 6 3 9 5 7 7 3 9 5 6 2 5 3 7 6 5 2 2 4 4 8 3 9 5 5 9 8 7 7 8 7 4 5 8 5\n",
      "Pred:  2 3 5 6 9 7 2 3 5 6 9 7 2 3 5 6 9 7 2 3 5 6 9 7 2 3 5 6 9 7 2 3 5 6 9 7 2 3 5 6 9 7 2 3 5 6 9 7 2 3 5 6 9 7 2 3 5 6 9 7 2 3 5 6 9 7 2 3 5 6 9 7 2 3 5 6 9 7 2 3 5 6 9 7 2 3 5 6 9 7 2 3 5 6 9 7 2 3 5 6\n",
      "Match:  0.1509433962264151\n",
      "\n",
      "Epoch 1\n",
      "Evaluation perplexity: 9.767495\n",
      "\n",
      "Example #1\n",
      "Src :  eight four nine six six eight three four eight four four nine six five nine nine four seven six three nine five seven seven three nine five six two five three seven six five two two four four eight three nine five five nine eight seven seven eight seven four five eight five\n",
      "Trg :  8 4 9 6 6 8 3 4 8 4 4 9 6 5 9 9 4 7 6 3 9 5 7 7 3 9 5 6 2 5 3 7 6 5 2 2 4 4 8 3 9 5 5 9 8 7 7 8 7 4 5 8 5\n",
      "Pred:  2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7\n",
      "Match:  0.11320754716981132\n",
      "\n",
      "Epoch 2\n",
      "Evaluation perplexity: 9.605982\n",
      "\n",
      "Example #1\n",
      "Src :  eight four nine six six eight three four eight four four nine six five nine nine four seven six three nine five seven seven three nine five six two five three seven six five two two four four eight three nine five five nine eight seven seven eight seven four five eight five\n",
      "Trg :  8 4 9 6 6 8 3 4 8 4 4 9 6 5 9 9 4 7 6 3 9 5 7 7 3 9 5 6 2 5 3 7 6 5 2 2 4 4 8 3 9 5 5 9 8 7 7 8 7 4 5 8 5\n",
      "Pred:  2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7 2 3 5 6 7\n",
      "Match:  0.11320754716981132\n",
      "\n",
      "Epoch 3\n",
      "Evaluation perplexity: 9.463161\n",
      "\n",
      "Example #1\n",
      "Src :  eight four nine six six eight three four eight four four nine six five nine nine four seven six three nine five seven seven three nine five six two five three seven six five two two four four eight three nine five five nine eight seven seven eight seven four five eight five\n",
      "Trg :  8 4 9 6 6 8 3 4 8 4 4 9 6 5 9 9 4 7 6 3 9 5 7 7 3 9 5 6 2 5 3 7 6 5 2 2 4 4 8 3 9 5 5 9 8 7 7 8 7 4 5 8 5\n",
      "Pred:  2 3 5 6 7 2 3 5 6 7 2 3 3 5 6 7 2 3 3 5 6 7 2 3 3 5 6 7 2 3 3 5 6 7 2 3 3 5 6 7 2 3 3 5 6 7 2 3 3 5 6 7 2 3 3 5 6 7 2 3 3 5 6 7 2 3 3 5 6 7 2 3 3 5 6 7 2 3 3 5 6 7 2 3 3 5 6 7 2 3 3 5 6 7 2 3 3 5 6 7\n",
      "Match:  0.16981132075471697\n",
      "\n",
      "Epoch 4\n"
     ]
    }
   ],
   "source": [
    "dev_perplexities,hypotheses,alphas,src_ex,trg_ex = train_trans_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "r3mTnjJesT8P"
   },
   "outputs": [],
   "source": [
    "def plot_perplexity(perplexities):\n",
    "    \"\"\"plot perplexities\"\"\"\n",
    "    plt.title(\"Perplexity per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Perplexity\")\n",
    "    plt.plot(perplexities)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "A5hCa-sJsT8T"
   },
   "outputs": [],
   "source": [
    "plot_perplexity(dev_perplexities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "he4a6Tj0Ayb_"
   },
   "source": [
    "# Attention visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "g-LF3rcLAyb_"
   },
   "outputs": [],
   "source": [
    "def plot_heatmap(src, trg, scores):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(50,50))\n",
    "    heatmap = ax.pcolor(scores, cmap='PuRd')\n",
    "\n",
    "    ax.set_xticklabels(trg, minor=False, rotation='vertical', size=50)\n",
    "    ax.set_yticklabels(src, minor=False,size=50)\n",
    "\n",
    "    # put the major ticks at the middle of each cell\n",
    "    # and the x-ticks on top\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.set_xticks(np.arange(scores.shape[1]) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(scores.shape[0]) + 0.5, minor=False)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    cbar=plt.colorbar(heatmap)\n",
    "    cbar.ax.tick_params(labelsize=50, width=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Y0tqBctXAycC"
   },
   "outputs": [],
   "source": [
    "# This plots a chosen sentence, for which we saved the attention scores above.\n",
    "\n",
    "src_text = \"\".join(turn_num_to_text(src_ex))\n",
    "pred_ex = hypotheses[0]\n",
    "pred_attn = alphas[0][0].T[:, :len(pred_ex)]\n",
    "\n",
    "print(\"src\", src_text)\n",
    "print(\"ref\", trg_ex)\n",
    "print(\"pred\", pred_ex)\n",
    "plot_heatmap(src_text, pred_ex, pred_attn)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "fMXg83uCsT7E",
    "2vLDCPXKsT7K"
   ],
   "name": "annotated_encoder_decoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
