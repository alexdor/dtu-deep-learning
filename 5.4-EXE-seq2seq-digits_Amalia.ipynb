{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq - Encoder/Decoder networks\n",
    "In this exercise we'll have a deeper look into the ability to use multiple RNN's to infer and generate sequences of data.\n",
    "Specifically we will implement a Encoder-Decoder RNN based for a simple sequence to sequence translation task.\n",
    "This type of models have shown impressive performance in Neural Machine Translation and Image Caption generation. \n",
    "\n",
    "In the encoder-decoder structure one RNN (blue) encodes the input into a hidden representation, and a second RNN (red) uses this representation to predict the target values.\n",
    "An essential step is deciding how the encoder and decoder should communicate.\n",
    "In the simplest approach you use the last hidden state of the encoder to initialize the decoder.\n",
    "This is what we will do in this notebook, as shown here:\n",
    "\n",
    "![](./images/enc-dec.png)\n",
    "\n",
    "In this exercise we will translate from the words of number (e.g. 'nine') to the actual number (e.g. '9').\n",
    "The input for the Encoder RNN consists of words defining the number, whilst the output of such an encoding serves as input for the Decoder RNN that aims to generate generate a number. \n",
    "Our dataset is generated and consists of numbers and an End-of-Sentence (EOS) character ('#'). The data we want to generate should be like follows:\n",
    "\n",
    "```\n",
    "Examples: \n",
    "prediction  |  input\n",
    "991136#00 \t nine nine one one three six\n",
    "81771#000 \t eight one seven seven one\n",
    "3519614#0 \t three five one nine six one four\n",
    "26656#000 \t two six six five six\n",
    "60344#000 \t six zero three four four\n",
    "162885#00 \t one six two eight eight five\n",
    "78612625# \t seven eight six one two six two five\n",
    "9464710#0 \t nine four six four seven one zero\n",
    "191306#00 \t one nine one three zero six\n",
    "10160378# \t one zero one zero six three seven eight\n",
    "```\n",
    "\n",
    "Let us define the space of characters and numbers to be learned with the networks:\n",
    "\n",
    "```\n",
    "Number of valid characters: 27\n",
    "'0'=0,\t'1'=1,\t'2'=2,\t'3'=3,\t'4'=4,\t'5'=5,\t'6'=6,\t'7'=7,\t'8'=8,\t'9'=9,\t'#'=10,\t' '=11,\t'e'=12,\t'g'=13,\t'f'=14,\t'i'=15,\t'h'=16,\t'o'=17,\t'n'=18,\t's'=19,\t'r'=20,\t'u'=21,\t't'=22,\t'w'=23,\t'v'=24,\t'x'=25,\t'z'=26,\t\n",
    "Stop/start character = #\n",
    "```\n",
    "\n",
    "All represented characters and numbers as characters, gets mapped to an integer from 0-26. Our total space of valid characters consists of 27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Device in use: cpu\n"
    }
   ],
   "source": [
    "from data_generator import generate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from data_generator import generate\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device in use:\", device)\n",
    "\n",
    "NUM_INPUTS = 27 #No. of possible characters\n",
    "NUM_OUTPUTS = 11  # (0-9 + '#')\n",
    "\n",
    "### Hyperparameters and general configs\n",
    "MAX_SEQ_LEN = 8\n",
    "MIN_SEQ_LEN = 5\n",
    "BATCH_SIZE = 8\n",
    "TRAINING_SIZE = 8000\n",
    "LEARNING_RATE = 0.003\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# Hidden size of enc and dec need to be equal if last hidden of encoder becomes init hidden of decoder\n",
    "# Otherwise we would need e.g. a linear layer to map to a space with the correct dimension\n",
    "NUM_UNITS_ENC = NUM_UNITS_DEC = 256\n",
    "HIDDEN_DIM = 512\n",
    "TEST_SIZE = 1000\n",
    "EPOCHS = 10\n",
    "TEACHER_FORCING = True\n",
    "NUM_OF_BATCHES=8\n",
    "\n",
    "assert TRAINING_SIZE % BATCH_SIZE == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we won´t worry about data generation, but utilise a built function for this purpose. The function generates random data constained by the 27 characters described above.\n",
    "\n",
    "The encoder takes as input the embedded text strings generated from the *generate* function as given here above ie. 'nine' would become [18 15 18 12].\n",
    "Sequeneces are generated at random given settings of minima and maxima length, constrained by the dimensions of the two RNN´s architecture.\n",
    "We may visualise a subset of the data generated by running the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "our six three three', 'four five', 'six three one', 'zero nine', 'zero eight nine', 'six zero four three', 'two nine three three', 'nine zero one', 'two seven nine', 'six eight zero nine', 'zero two four', 'zero three four four', 'four six', 'eight five', 'two seven zero', 'zero eight', 'three zero six five', 'five five zero seven', 'zero three', 'zero five seven three', 'six five two', 'five two zero four', 'seven zero', 'six five seven four', 'nine four eight three', 'eight one zero four', 'three four nine nine', 'six five one five', 'two three zero', 'two five', 'seven four four', 'eight zero nine', 'seven six', 'two three nine', 'seven nine', 'zero five zero zero', 'three nine', 'six seven', 'two nine seven', 'eight nine one two', 'five nine', 'zero five five', 'four six zero three', 'five nine', 'six seven four six', 'eight one six three', 'seven six seven seven', 'two nine zero four', 'nine two nine', 'eight seven one', 'seven zero', 'one six seven eight', 'two eight', 'five zero zero', 'five six one eight', 'one six two', 'eight one one three', 'four four zero one', 'zero four eight six', 'two eight seven', 'three six nine nine', 'five four one', 'five seven nine seven', 'four nine five five', 'eight one four', 'seven one', 'one six', 'eight two zero', 'seven one three three', 'zero two zero nine', 'zero seven two six', 'two one', 'seven three nine', 'two zero', 'four six', 'six four five', 'zero eight', 'four eight five', 'six seven nine', 'five six zero three', 'zero one nine five', 'five zero', 'eight zero four five', 'six seven', 'nine three', 'one five nine', 'two three', 'three two five', 'nine two five seven', 'six two nine', 'two seven', 'four one', 'three one', 'seven five four', 'zero three five', 'five seven one', 'seven four three', 'one three two six', 'three zero', 'one nine', 'two nine zero', 'five nine three', 'eight seven two', 'nine one five', 'eight three two', 'zero nine', 'three eight four five', 'seven three one', 'eight six seven', 'two one zero five', 'three six three', 'four six six seven', 'six four', 'eight three eight seven', 'three five eight four', 'five zero one nine', 'seven four', 'six nine nine two', 'three zero zero', 'one one five', 'nine seven three zero', 'zero one', 'two two five', 'seven one', 'zero zero six', 'five two zero', 'four eight three two', 'two one eight', 'four six two', 'five three nine seven', 'nine nine four', 'seven zero one', 'seven zero', 'seven eight nine eight', 'zero seven three', 'one four', 'eight four four two', 'three two one nine', 'one six', 'seven two seven', 'two seven', 'eight seven four zero', 'one two', 'one one', 'six nine eight seven', 'seven four', 'five eight one', 'four five', 'two one', 'five two', 'zero seven', 'zero zero', 'six three five', 'nine eight seven', 'three nine six', 'two seven', 'one three three', 'zero eight', 'eight three three eight', 'eight five nine', 'six two six', 'three nine two seven', 'eight three five', 'one zero', 'one zero', 'one four two', 'five six seven three', 'zero eight two', 'seven seven one five', 'four one', 'two zero zero four', 'nine seven', 'six eight zero', 'four eight', 'eight eight eight', 'seven nine one six', 'four nine nine', 'one two', 'five one seven', 'six seven', 'four five seven zero', 'two five five seven', 'eight seven eight', 'three three four six']\nENCODED INPUTS:\t\t\t [[26 21 17 ... 17 19 20]\n [26 21 17 ... 14 26 26]\n [20 19 14 ... 12 26 22]\n ...\n [25 22 26 ...  0  0  0]\n [20 18 25 ...  0  0  0]\n [13 21 15 ...  0  0  0]]\nINPUTS SEQUENCE LENGTH:\t [[23 22 23 22 23 23 22 23]]\nTEXT TARGETS INPUT:\t\t ['#6420', '#77', '#23', '#422', '#7651', '#766', '#7354', '#099', '#74', '#69', '#507', '#48', '#3108', '#452', '#849', '#762', '#785', '#17', '#5816', '#76', '#05', '#304', '#583', '#48', '#103', '#59', '#702', '#1784', '#750', '#85', '#60', '#28', '#60', '#9648', '#421', '#7628', '#5270', '#965', '#77', '#272', '#976', '#8533', '#017', '#72', '#703', '#4806', '#5612', '#4163', '#713', '#96', '#774', '#844', '#690', '#15', '#333', '#19', '#218', '#3105', '#9070', '#31', '#919', '#4346', '#82', '#6053', '#6320', '#524', '#14', '#479', '#81', '#3387', '#15', '#590', '#925', '#8818', '#8178', '#214', '#931', '#669', '#238', '#75', '#31', '#1832', '#6325', '#0566', '#939', '#295', '#9701', '#13', '#51', '#905', '#2311', '#86', '#28', '#1195', '#14', '#67', '#61', '#50', '#607', '#616', '#450', '#473', '#033', '#1459', '#04', '#4790', '#409', '#92', '#220', '#9136', '#761', '#16', '#09', '#943', '#39', '#09', '#8820', '#2479', '#7221', '#492', '#9720', '#201', '#422', '#36', '#47', '#521', '#913', '#4587', '#02', '#349', '#6188', '#537', '#75', '#972', '#04', '#6127', '#476', '#28', '#4358', '#165', '#6530', '#37', '#397', '#37', '#1539', '#935', '#8333', '#011', '#281', '#618', '#6829', '#03', '#28', '#63', '#6364', '#7690', '#3543', '#94', '#3128', '#13', '#8910', '#33', '#0568', '#882', '#34', '#493', '#95', '#3161', '#5327', '#4866', '#6347', '#4747', '#9890', '#67', '#334', '#151', '#507', '#65', '#27', '#120', '#803', '#81', '#393', '#8525', '#24', '#26', '#128', '#6310', '#843', '#5902', '#423', '#066', '#2196', '#2251', '#956', '#18', '#640', '#401', '#7618', '#595', '#29', '#44', '#82', '#53', '#8426', '#22', '#251', '#8399', '#993', '#159', '#946', '#8604', '#901', '#88', '#094', '#877', '#6136', '#06', '#6232', '#40', '#25', '#8957', '#820', '#0458', '#6805', '#682', '#94', '#207', '#088', '#34', '#07', '#999', '#2196', '#8409', '#9711', '#942', '#90', '#2879', '#7760', '#53', '#890', '#992', '#98', '#638', '#90', '#6840', '#218', '#18', '#311', '#993', '#204', '#5745', '#810', '#563', '#31', '#3871', '#406', '#3779', '#767', '#62', '#87', '#611', '#02', '#5937', '#2692', '#2395', '#8986', '#658', '#656', '#5647', '#945', '#16', '#891', '#774', '#3122', '#97', '#552', '#0836', '#745', '#273', '#030', '#31', '#9248', '#772', '#7386', '#487', '#9229', '#5580', '#279', '#21', '#3136', '#2236', '#176', '#122', '#9009', '#72', '#77', '#97', '#3453', '#18', '#5379', '#043', '#648', '#57', '#5132', '#00', '#5226', '#122', '#381', '#9404', '#987', '#39', '#931', '#488', '#480', '#5341', '#4811', '#5943', '#0970', '#9418', '#5907', '#8588', '#889', '#38', '#102', '#0869', '#934', '#28', '#026', '#61', '#4631', '#09', '#2496', '#5704', '#5336', '#64', '#9775', '#6494', '#60', '#8196', '#94', '#710', '#4697', '#68', '#68', '#97', '#4877', '#825', '#92', '#355', '#588', '#42', '#87', '#299', '#5530', '#9096', '#98', '#9104', '#7143', '#336', '#286', '#809', '#35', '#6398', '#197', '#5482', '#634', '#7721', '#7319', '#4708', '#46', '#53', '#1828', '#8607', '#24', '#803', '#25', '#1103', '#41', '#359', '#2342', '#33', '#06', '#22', '#9165', '#11', '#956', '#16', '#90', '#617', '#70', '#96', '#95', '#8456', '#53', '#142', '#69', '#9543', '#93', '#1280', '#74', '#556', '#71', '#64', '#4958', '#3452', '#49', '#7115', '#94', '#06', '#755', '#501', '#858', '#4752', '#577', '#0852', '#3066', '#54', '#275', '#518', '#2658', '#652', '#818', '#0914', '#1214', '#380', '#853', '#319', '#8089', '#5171', '#16', '#2252', '#4642', '#3987', '#123', '#484', '#720', '#55', '#081', '#6621', '#780', '#82', '#26', '#147', '#1424', '#47', '#2547', '#58', '#0076', '#5743', '#2001', '#5466', '#95', '#670', '#9303', '#8131', '#6709', '#823', '#9866', '#0024', '#192', '#65', '#26', '#468', '#3226', '#93', '#87', '#98', '#571', '#5597', '#32', '#247', '#033', '#7389', '#414', '#809', '#4383', '#0498', '#27', '#965', '#539', '#09', '#197', '#3766', '#83', '#27', '#729', '#2517', '#2960', '#64', '#92', '#598', '#68', '#42', '#6474', '#5606', '#323', '#64', '#88', '#66', '#284', '#257', '#38', '#97', '#2676', '#8569', '#262', '#232', '#42', '#2005', '#064', '#982', '#641', '#7009', '#701', '#229', '#56', '#4655', '#0094', '#60', '#9801', '#24', '#044', '#6769', '#612', '#0673', '#1011', '#80', '#24', '#3301', '#5069', '#11', '#40', '#525', '#543', '#378', '#1819', '#97', '#572', '#1709', '#28', '#89', '#366', '#884', '#09', '#77', '#775', '#99', '#903', '#98', '#26', '#06', '#6568', '#724', '#331', '#11', '#440', '#0632', '#86', '#96', '#590', '#998', '#01', '#1459', '#8522', '#32', '#9000', '#95', '#14', '#094', '#5888', '#46', '#128', '#6948', '#9692', '#833', '#971', '#85', '#1316', '#8444', '#089', '#556', '#745', '#12', '#480', '#4969', '#10', '#4035', '#523', '#419', '#48', '#75', '#2514', '#8199', '#08', '#7000', '#795', '#55', '#55', '#9392', '#698', '#160', '#661', '#9195', '#39', '#44', '#23', '#9678', '#9680', '#94', '#38', '#866', '#3400', '#8702', '#7485', '#6376', '#77', '#0929', '#34', '#6109', '#900', '#19', '#465', '#458', '#796', '#47', '#077', '#66', '#0589', '#564', '#387', '#44', '#098', '#1135', '#854', '#594', '#49', '#705', '#2076', '#5344', '#64', '#71', '#22', '#92', '#36', '#4520', '#95', '#993', '#456', '#266', '#83', '#512', '#82', '#67', '#965', '#968', '#6166', '#2466', '#6510', '#243', '#645', '#630', '#50', '#2820', '#059', '#9037', '#71', '#582', '#967', '#29', '#2187', '#35', '#1805', '#94', '#75', '#1910', '#328', '#490', '#641', '#800', '#577', '#9516', '#391', '#087', '#6360', '#114', '#402', '#966', '#57', '#471', '#603', '#009', '#4165', '#59', '#912', '#8681', '#9523', '#9687', '#364', '#36', '#9005', '#298', '#22', '#7167', '#13', '#60', '#35', '#2455', '#2211', '#901', '#22', '#398', '#441', '#396', '#5466', '#331', '#6120', '#662', '#38', '#022', '#6629', '#41', '#15', '#4574', '#7794', '#118', '#407', '#929', '#234', '#0614', '#3468', '#40', '#79', '#743', '#1584', '#0398', '#09', '#53', '#564', '#755', '#752', '#76', '#971', '#920', '#258', '#5900', '#7822', '#80', '#66', '#57', '#063', '#97', '#20', '#3907', '#4313', '#98', '#09', '#00', '#296', '#9009', '#0685', '#929', '#97', '#35', '#9739', '#2144', '#868', '#710', '#553', '#755', '#5812', '#07', '#883', '#146', '#783', '#303', '#2316', '#6119', '#7536', '#282', '#1114', '#20', '#4369', '#868', '#57', '#4724', '#517', '#169', '#9108', '#6851', '#4801', '#2039', '#73', '#6306', '#06', '#9852', '#9448', '#09', '#36', '#9923', '#338', '#3240', '#296', '#997', '#76', '#290', '#6407', '#559', '#0969', '#97', '#9637', '#99', '#3835', '#70', '#177', '#479', '#4633', '#45', '#631', '#09', '#089', '#6043', '#2933', '#901', '#279', '#6809', '#024', '#0344', '#46', '#85', '#270', '#08', '#3065', '#5507', '#03', '#0573', '#652', '#5204', '#70', '#6574', '#9483', '#8104', '#3499', '#6515', '#230', '#25', '#744', '#809', '#76', '#239', '#79', '#0500', '#39', '#67', '#297', '#8912', '#59', '#055', '#4603', '#59', '#6746', '#8163', '#7677', '#2904', '#929', '#871', '#70', '#1678', '#28', '#500', '#5618', '#162', '#8113', '#4401', '#0486', '#287', '#3699', '#541', '#5797', '#4955', '#814', '#71', '#16', '#820', '#7133', '#0209', '#0726', '#21', '#739', '#20', '#46', '#645', '#08', '#485', '#679', '#5603', '#0195', '#50', '#8045', '#67', '#93', '#159', '#23', '#325', '#9257', '#629', '#27', '#41', '#31', '#754', '#035', '#571', '#743', '#1326', '#30', '#19', '#290', '#593', '#872', '#915', '#832', '#09', '#3845', '#731', '#867', '#2105', '#363', '#4667', '#64', '#8387', '#3584', '#5019', '#74', '#6992', '#300', '#115', '#9730', '#01', '#225', '#71', '#006', '#520', '#4832', '#218', '#462', '#5397', '#994', '#701', '#70', '#7898', '#073', '#14', '#8442', '#3219', '#16', '#727', '#27', '#8740', '#12', '#11', '#6987', '#74', '#581', '#45', '#21', '#52', '#07', '#00', '#635', '#987', '#396', '#27', '#133', '#08', '#8338', '#859', '#626', '#3927', '#835', '#10', '#10', '#142', '#5673', '#082', '#7715', '#41', '#2004', '#97', '#680', '#48', '#888', '#7916', '#499', '#12', '#517', '#67', '#4570', '#2557', '#878', '#3346']\nTEXT TARGETS OUTPUT:\t ['6420#', '77#', '23#', '422#', '7651#', '766#', '7354#', '099#', '74#', '69#', '507#', '48#', '3108#', '452#', '849#', '762#', '785#', '17#', '5816#', '76#', '05#', '304#', '583#', '48#', '103#', '59#', '702#', '1784#', '750#', '85#', '60#', '28#', '60#', '9648#', '421#', '7628#', '5270#', '965#', '77#', '272#', '976#', '8533#', '017#', '72#', '703#', '4806#', '5612#', '4163#', '713#', '96#', '774#', '844#', '690#', '15#', '333#', '19#', '218#', '3105#', '9070#', '31#', '919#', '4346#', '82#', '6053#', '6320#', '524#', '14#', '479#', '81#', '3387#', '15#', '590#', '925#', '8818#', '8178#', '214#', '931#', '669#', '238#', '75#', '31#', '1832#', '6325#', '0566#', '939#', '295#', '9701#', '13#', '51#', '905#', '2311#', '86#', '28#', '1195#', '14#', '67#', '61#', '50#', '607#', '616#', '450#', '473#', '033#', '1459#', '04#', '4790#', '409#', '92#', '220#', '9136#', '761#', '16#', '09#', '943#', '39#', '09#', '8820#', '2479#', '7221#', '492#', '9720#', '201#', '422#', '36#', '47#', '521#', '913#', '4587#', '02#', '349#', '6188#', '537#', '75#', '972#', '04#', '6127#', '476#', '28#', '4358#', '165#', '6530#', '37#', '397#', '37#', '1539#', '935#', '8333#', '011#', '281#', '618#', '6829#', '03#', '28#', '63#', '6364#', '7690#', '3543#', '94#', '3128#', '13#', '8910#', '33#', '0568#', '882#', '34#', '493#', '95#', '3161#', '5327#', '4866#', '6347#', '4747#', '9890#', '67#', '334#', '151#', '507#', '65#', '27#', '120#', '803#', '81#', '393#', '8525#', '24#', '26#', '128#', '6310#', '843#', '5902#', '423#', '066#', '2196#', '2251#', '956#', '18#', '640#', '401#', '7618#', '595#', '29#', '44#', '82#', '53#', '8426#', '22#', '251#', '8399#', '993#', '159#', '946#', '8604#', '901#', '88#', '094#', '877#', '6136#', '06#', '6232#', '40#', '25#', '8957#', '820#', '0458#', '6805#', '682#', '94#', '207#', '088#', '34#', '07#', '999#', '2196#', '8409#', '9711#', '942#', '90#', '2879#', '7760#', '53#', '890#', '992#', '98#', '638#', '90#', '6840#', '218#', '18#', '311#', '993#', '204#', '5745#', '810#', '563#', '31#', '3871#', '406#', '3779#', '767#', '62#', '87#', '611#', '02#', '5937#', '2692#', '2395#', '8986#', '658#', '656#', '5647#', '945#', '16#', '891#', '774#', '3122#', '97#', '552#', '0836#', '745#', '273#', '030#', '31#', '9248#', '772#', '7386#', '487#', '9229#', '5580#', '279#', '21#', '3136#', '2236#', '176#', '122#', '9009#', '72#', '77#', '97#', '3453#', '18#', '5379#', '043#', '648#', '57#', '5132#', '00#', '5226#', '122#', '381#', '9404#', '987#', '39#', '931#', '488#', '480#', '5341#', '4811#', '5943#', '0970#', '9418#', '5907#', '8588#', '889#', '38#', '102#', '0869#', '934#', '28#', '026#', '61#', '4631#', '09#', '2496#', '5704#', '5336#', '64#', '9775#', '6494#', '60#', '8196#', '94#', '710#', '4697#', '68#', '68#', '97#', '4877#', '825#', '92#', '355#', '588#', '42#', '87#', '299#', '5530#', '9096#', '98#', '9104#', '7143#', '336#', '286#', '809#', '35#', '6398#', '197#', '5482#', '634#', '7721#', '7319#', '4708#', '46#', '53#', '1828#', '8607#', '24#', '803#', '25#', '1103#', '41#', '359#', '2342#', '33#', '06#', '22#', '9165#', '11#', '956#', '16#', '90#', '617#', '70#', '96#', '95#', '8456#', '53#', '142#', '69#', '9543#', '93#', '1280#', '74#', '556#', '71#', '64#', '4958#', '3452#', '49#', '7115#', '94#', '06#', '755#', '501#', '858#', '4752#', '577#', '0852#', '3066#', '54#', '275#', '518#', '2658#', '652#', '818#', '0914#', '1214#', '380#', '853#', '319#', '8089#', '5171#', '16#', '2252#', '4642#', '3987#', '123#', '484#', '720#', '55#', '081#', '6621#', '780#', '82#', '26#', '147#', '1424#', '47#', '2547#', '58#', '0076#', '5743#', '2001#', '5466#', '95#', '670#', '9303#', '8131#', '6709#', '823#', '9866#', '0024#', '192#', '65#', '26#', '468#', '3226#', '93#', '87#', '98#', '571#', '5597#', '32#', '247#', '033#', '7389#', '414#', '809#', '4383#', '0498#', '27#', '965#', '539#', '09#', '197#', '3766#', '83#', '27#', '729#', '2517#', '2960#', '64#', '92#', '598#', '68#', '42#', '6474#', '5606#', '323#', '64#', '88#', '66#', '284#', '257#', '38#', '97#', '2676#', '8569#', '262#', '232#', '42#', '2005#', '064#', '982#', '641#', '7009#', '701#', '229#', '56#', '4655#', '0094#', '60#', '9801#', '24#', '044#', '6769#', '612#', '0673#', '1011#', '80#', '24#', '3301#', '5069#', '11#', '40#', '525#', '543#', '378#', '1819#', '97#', '572#', '1709#', '28#', '89#', '366#', '884#', '09#', '77#', '775#', '99#', '903#', '98#', '26#', '06#', '6568#', '724#', '331#', '11#', '440#', '0632#', '86#', '96#', '590#', '998#', '01#', '1459#', '8522#', '32#', '9000#', '95#', '14#', '094#', '5888#', '46#', '128#', '6948#', '9692#', '833#', '971#', '85#', '1316#', '8444#', '089#', '556#', '745#', '12#', '480#', '4969#', '10#', '4035#', '523#', '419#', '48#', '75#', '2514#', '8199#', '08#', '7000#', '795#', '55#', '55#', '9392#', '698#', '160#', '661#', '9195#', '39#', '44#', '23#', '9678#', '9680#', '94#', '38#', '866#', '3400#', '8702#', '7485#', '6376#', '77#', '0929#', '34#', '6109#', '900#', '19#', '465#', '458#', '796#', '47#', '077#', '66#', '0589#', '564#', '387#', '44#', '098#', '1135#', '854#', '594#', '49#', '705#', '2076#', '5344#', '64#', '71#', '22#', '92#', '36#', '4520#', '95#', '993#', '456#', '266#', '83#', '512#', '82#', '67#', '965#', '968#', '6166#', '2466#', '6510#', '243#', '645#', '630#', '50#', '2820#', '059#', '9037#', '71#', '582#', '967#', '29#', '2187#', '35#', '1805#', '94#', '75#', '1910#', '328#', '490#', '641#', '800#', '577#', '9516#', '391#', '087#', '6360#', '114#', '402#', '966#', '57#', '471#', '603#', '009#', '4165#', '59#', '912#', '8681#', '9523#', '9687#', '364#', '36#', '9005#', '298#', '22#', '7167#', '13#', '60#', '35#', '2455#', '2211#', '901#', '22#', '398#', '441#', '396#', '5466#', '331#', '6120#', '662#', '38#', '022#', '6629#', '41#', '15#', '4574#', '7794#', '118#', '407#', '929#', '234#', '0614#', '3468#', '40#', '79#', '743#', '1584#', '0398#', '09#', '53#', '564#', '755#', '752#', '76#', '971#', '920#', '258#', '5900#', '7822#', '80#', '66#', '57#', '063#', '97#', '20#', '3907#', '4313#', '98#', '09#', '00#', '296#', '9009#', '0685#', '929#', '97#', '35#', '9739#', '2144#', '868#', '710#', '553#', '755#', '5812#', '07#', '883#', '146#', '783#', '303#', '2316#', '6119#', '7536#', '282#', '1114#', '20#', '4369#', '868#', '57#', '4724#', '517#', '169#', '9108#', '6851#', '4801#', '2039#', '73#', '6306#', '06#', '9852#', '9448#', '09#', '36#', '9923#', '338#', '3240#', '296#', '997#', '76#', '290#', '6407#', '559#', '0969#', '97#', '9637#', '99#', '3835#', '70#', '177#', '479#', '4633#', '45#', '631#', '09#', '089#', '6043#', '2933#', '901#', '279#', '6809#', '024#', '0344#', '46#', '85#', '270#', '08#', '3065#', '5507#', '03#', '0573#', '652#', '5204#', '70#', '6574#', '9483#', '8104#', '3499#', '6515#', '230#', '25#', '744#', '809#', '76#', '239#', '79#', '0500#', '39#', '67#', '297#', '8912#', '59#', '055#', '4603#', '59#', '6746#', '8163#', '7677#', '2904#', '929#', '871#', '70#', '1678#', '28#', '500#', '5618#', '162#', '8113#', '4401#', '0486#', '287#', '3699#', '541#', '5797#', '4955#', '814#', '71#', '16#', '820#', '7133#', '0209#', '0726#', '21#', '739#', '20#', '46#', '645#', '08#', '485#', '679#', '5603#', '0195#', '50#', '8045#', '67#', '93#', '159#', '23#', '325#', '9257#', '629#', '27#', '41#', '31#', '754#', '035#', '571#', '743#', '1326#', '30#', '19#', '290#', '593#', '872#', '915#', '832#', '09#', '3845#', '731#', '867#', '2105#', '363#', '4667#', '64#', '8387#', '3584#', '5019#', '74#', '6992#', '300#', '115#', '9730#', '01#', '225#', '71#', '006#', '520#', '4832#', '218#', '462#', '5397#', '994#', '701#', '70#', '7898#', '073#', '14#', '8442#', '3219#', '16#', '727#', '27#', '8740#', '12#', '11#', '6987#', '74#', '581#', '45#', '21#', '52#', '07#', '00#', '635#', '987#', '396#', '27#', '133#', '08#', '8338#', '859#', '626#', '3927#', '835#', '10#', '10#', '142#', '5673#', '082#', '7715#', '41#', '2004#', '97#', '680#', '48#', '888#', '7916#', '499#', '12#', '517#', '67#', '4570#', '2557#', '878#', '3346#']\nENCODED TARGETS INPUT:\t [[10  6  4  2  0]\n [10  2  6  7  6]\n [10  5  6  0  6]\n ...\n [10  2  8  0  0]\n [10  4  4  0  0]\n [10  6  6  0  0]]\nENCODED TARGETS OUTPUT:\t [[ 6  4  2  0 10]\n [ 2  6  7  6 10]\n [ 5  6  0  6 10]\n ...\n [ 2  8 10  0  0]\n [ 4  4 10  0  0]\n [ 6  6 10  0  0]]\nTARGETS SEQUENCE LENGTH: [[5 5 5 5 5 5 5 5]]\nTARGETS MASK:\t\t\t [1. 1. 1. 0. 0.]\n"
    }
   ],
   "source": [
    "!python data_generator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's define the two RNN's\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "            \n",
    "        self.embedding = nn.Embedding(input_size, self.hidden_size)\n",
    "        #rnn = nn.GRU\n",
    "        self.rnn = nn.LSTM(self.hidden_size, self.hidden_size,n_layers, dropout = dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        # Input shape [batch, seq_in_len]\n",
    "        # inputs = [inputs[0],inputs[2]]\n",
    "        inputs = inputs.long()\n",
    "\n",
    "\n",
    "        # Embedded shape [batch, seq_in_len, embed]\n",
    "        embedded = self.dropout(self.embedding(inputs))\n",
    "        #embedded = embedded.view(embedded.shape[0]*embedded.shape[1],embedded.shape[2],embedded.shape[3])\n",
    "        \n",
    "        # Output shape [batch, seq_in_len, embed]\n",
    "        # Hidden shape [1, batch, embed], last hidden state of the GRU cell\n",
    "        # We will feed this last hidden state into the decoder\n",
    "        #print(embedded.shape)\n",
    "       # Reshape our output to match the input shape of our forward pass\n",
    "        #hidden = hidden.reshape(hidden.shape[0],1, hidden.shape[1],hidden.shape[2])\n",
    "        #hidden=hidden.unsqueeze_(0)\n",
    "        #print(hidden[1].shape)\n",
    "        #view(len(sentence), 1, -1)\n",
    "        #print(test.shape)\n",
    "        outputs,hidden = self.rnn(embedded)\n",
    "        #print(hidden.shape)\n",
    "        return outputs,hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        init = torch.zeros(1, batch_size, self.hidden_size, device=device)\n",
    "        return init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size,n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        #rnn = nn.GRU\n",
    "        self.rnn = nn.LSTM(self.hidden_size, self.hidden_size,n_layers, dropout = dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs, hidden, output_len, teacher_forcing=False):\n",
    "        # Input shape: [batch, output_len]\n",
    "        # Hidden shape: [seq_len=1, batch_size, hidden_dim] (the last hidden state of the encoder)\n",
    "\n",
    "        if teacher_forcing:\n",
    "            dec_input = inputs\n",
    "            embed = self.dropout(self.embedding(dec_input))   # shape [batch, output_len, hidden_dim]\n",
    "            out, hidden = self.rnn(embed,hidden)\n",
    "            #out, hidden = self.rnn(embed, hidden)\n",
    "            out = self.out(out)  # linear layer, out has now shape [batch, output_len, output_size]\n",
    "            output = F.log_softmax(out, -1)\n",
    "        else:\n",
    "            # Take the EOS character only, for the whole batch, and unsqueeze so shape is [batch, 1]\n",
    "            # This is the first input, then we will use as input the GRU output at the previous time step\n",
    "            dec_input = inputs[:, 0].unsqueeze(1)\n",
    "\n",
    "            output = []\n",
    "            for i in range(output_len):\n",
    "                embed = self.dropout(self.embedding(dec_input))\n",
    "                out, hidden= self.rnn(embed,hidden)\n",
    "                #out, hidden = self.rnn(self.embedding(dec_input), hidden)\n",
    "                out = self.out(out)  # linear layer, out has now shape [batch, 1, output_size]\n",
    "                out = F.log_softmax(out, -1)\n",
    "                output.append(out.squeeze(1))\n",
    "                out_symbol = torch.argmax(out, dim=2)   # shape [batch, 1]\n",
    "                dec_input = out_symbol   # feed the decoded symbol back into the recurrent unit at next step\n",
    "\n",
    "            output = torch.stack(output).permute(1, 0, 2)  # [batch_size x seq_len x output_size]\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learned representation from the *Encoder* gets propagated to the *Decoder* as the final hidden layer in the *Encoder* network is set as initialisation for the *Decoder*'s first hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(encoder, decoder, x, t, t_in, criterion, max_t_len, teacher_forcing):\n",
    "    \"\"\"\n",
    "    Executes a forward pass through the whole model.\n",
    "\n",
    "    :param encoder:\n",
    "    :param decoder:\n",
    "    :param x: input to the encoder, shape [batch, seq_in_len]\n",
    "    :param t: target output predictions for decoder, shape [batch, seq_t_len]\n",
    "    :param criterion: loss function\n",
    "    :param max_t_len: maximum target length\n",
    "\n",
    "    :return: output (after log-softmax), loss, accuracy (per-symbol)\n",
    "    \"\"\"\n",
    "    # Run encoder and get last hidden state (and output)\n",
    "    #print(x)\n",
    "    #print(len(x))\n",
    "    batch_size = len(x)\n",
    "    enc_h = encoder.init_hidden(batch_size)\n",
    "    enc_out, enc_h = encoder(x, enc_h)\n",
    "\n",
    "    dec_h = enc_h  # Init hidden state of decoder as hidden state of encoder\n",
    "    dec_input = t_in\n",
    "    out = decoder(dec_input, dec_h, max_t_len, teacher_forcing)\n",
    "    out = out.permute(0, 2, 1)\n",
    "    # Shape: [batch_size x num_classes x out_sequence_len], with second dim containing log probabilities\n",
    "\n",
    "    loss = criterion(out, t)\n",
    "    pred = get_pred(log_probs=out)\n",
    "    accuracy = (pred == t).type(torch.FloatTensor).mean()\n",
    "    return out, loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, decoder, inputs, targets, targets_in, criterion, enc_optimizer, dec_optimizer, epoch, max_t_len):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    for batch_idx, (x, t, t_in) in enumerate(zip(inputs, targets, targets_in)):\n",
    "        x = torch.LongTensor(x).to(device)\n",
    "        t = torch.LongTensor(t).to(device)\n",
    "        t_in = torch.LongTensor(t_in).to(device)\n",
    "       # print(batch_idx)\n",
    "#         inputs = inputs.to(device)\n",
    "#         targets = targets.long()\n",
    "#         targets_in = targets_in.long()\n",
    "        out, loss, accuracy = forward_pass(encoder, decoder, x, t, t_in, criterion, max_t_len,\n",
    "                                           teacher_forcing=TEACHER_FORCING)\n",
    "        enc_optimizer.zero_grad()\n",
    "        dec_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        enc_optimizer.step()\n",
    "        dec_optimizer.step()\n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Epoch {} [{}/{} ({:.0f}%)]\\tTraining loss: {:.4f} \\tTraining accuracy: {:.1f}%'.format(\n",
    "                epoch, batch_idx * len(x), TRAINING_SIZE,\n",
    "                100. * batch_idx * len(x) / TRAINING_SIZE, loss.item(),\n",
    "                100. * accuracy.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(encoder, decoder, inputs, targets, targets_in, criterion, max_t_len):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "#         inputs = inputs.to(device)\n",
    "#         print(targets)\n",
    "#         targets = targets.long()\n",
    "#         targets_in = targets_in.long()\n",
    "        out, loss, accuracy = forward_pass(encoder, decoder, inputs, targets, targets_in, criterion, max_t_len,\n",
    "                                           teacher_forcing=TEACHER_FORCING)\n",
    "    return out, loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers_to_text(seq):\n",
    "    return \"\".join([str(to_np(i)) if to_np(i) != 10 else '#' for i in seq])\n",
    "\n",
    "def to_np(x):\n",
    "    return x.cpu().numpy()\n",
    "\n",
    "def get_pred(log_probs):\n",
    "    \"\"\"\n",
    "    Get class prediction (digit prediction) from the net's output (the log_probs)\n",
    "    :param log_probs: Tensor of shape [batch_size x n_classes x sequence_len]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return torch.argmax(log_probs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "batch  0  starting\nbatch  0  ended with  1000\nbatch  1  starting\nbatch  1  ended with  1000\nbatch  2  starting\nbatch  2  ended with  1000\nbatch  3  starting\nbatch  3  ended with  1000\nbatch  4  starting\nbatch  4  ended with  1000\nbatch  5  starting\nbatch  5  ended with  1000\nbatch  6  starting\nbatch  6  ended with  1000\nbatch  7  starting\nbatch  7  ended with  1000\nGenerated batch length 8 from 1000 iterations\nbatch  0  starting\nbatch  0  ended with  1000\nGenerated batch length 1 from 1005 iterations\nEpoch 1 [0/8000 (0%)]\tTraining loss: 2.4002 \tTraining accuracy: 7.9%\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-78ec010698f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#print(inputs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#print(len(inputs[0][0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_target_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_val_target_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTest set: Average loss: {:.4f} \\tAccuracy: {:.3f}%\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-3d2c8a129fa2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, inputs, targets, targets_in, criterion, enc_optimizer, dec_optimizer, epoch, max_t_len)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0menc_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdec_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0menc_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdec_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(NUM_INPUTS, NUM_UNITS_ENC,N_LAYERS,DROPOUT).to(device)\n",
    "decoder = DecoderRNN(NUM_UNITS_DEC, NUM_OUTPUTS,N_LAYERS,DROPOUT).to(device)\n",
    "enc_optimizer = optim.RMSprop(encoder.parameters(), lr=LEARNING_RATE)\n",
    "dec_optimizer = optim.RMSprop(decoder.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get training set\n",
    "inputs, _, targets_in, targets, targets_seqlen, _, text, _, text_targ = generate(NUM_OF_BATCHES,TEST_SIZE, min_len=MIN_SEQ_LEN, max_len=MAX_SEQ_LEN)\n",
    "max_target_len = max(targets_seqlen)\n",
    "#inputs = torch.tensor(inputs)\n",
    "# inputs = torch.LongTensor(inputs)\n",
    "# targets = torch.LongTensor(targets)\n",
    "# targets_in = torch.LongTensor(targets_in)\n",
    "unique_text_targets = set([i for x in text_targ for i in x])\n",
    "\n",
    "# Get validation set\n",
    "val_inputs, _, val_targets_in, val_targets, val_targets_seqlen, _, val_text_in, _, val_text_targ = \\\n",
    "    generate(1,TEST_SIZE, min_len=MIN_SEQ_LEN, max_len=MAX_SEQ_LEN, invalid_set=unique_text_targets)\n",
    "#val_inputs = torch.tensor(val_inputs)\n",
    "val_inputs = torch.LongTensor(val_inputs).to(device)\n",
    "val_targets = torch.LongTensor(val_targets).to(device)\n",
    "val_targets_in = torch.LongTensor(val_targets_in).to(device)\n",
    "max_val_target_len = max(val_targets_seqlen)\n",
    "\n",
    "\n",
    "# Quick and dirty - just loop over training set without reshuffling\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    #print(inputs.shape)\n",
    "    #print(len(inputs[0][0]))\n",
    "    train(encoder, decoder, inputs, targets, targets_in, criterion, enc_optimizer, dec_optimizer, epoch, max_target_len)\n",
    "    _, loss, accuracy = test(encoder, decoder, val_inputs, val_targets, val_targets_in, criterion, max_val_target_len)\n",
    "    print('\\nTest set: Average loss: {:.4f} \\tAccuracy: {:.3f}%\\n'.format(loss, accuracy.item()*100.))\n",
    "\n",
    "    # Show examples\n",
    "    print(\"Examples: prediction | input\")\n",
    "    out, _, _ = test(encoder, decoder, val_inputs[:10], val_targets[:10], val_targets_in[:10], criterion, max_val_target_len)\n",
    "    pred = get_pred(out)\n",
    "    pred_text = [numbers_to_text(sample) for sample in pred]\n",
    "    for i in range(10):\n",
    "        print(pred_text[i], \"\\t\", val_text_in[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise:\n",
    "\n",
    "1. Implement missing code for the network in the *train* function. \n",
    "2. These networks implement the GRU-gates. Implement an alternative control utilising a memory mechanism (Hint: LSTM). What do you experience? \n",
    "3. (optional) There are some parameters in the model that may be optimized further, what could they be? Achieve >90% validation accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}